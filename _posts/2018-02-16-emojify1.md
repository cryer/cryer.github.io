---
layout: post
title: emojify系列（一）
description: 利用pytorch实现emojify
---

# 起因

前段时间完成了吴恩达的深度学习第五专题序列模型，里面一些作业都很有意思，包括这个Emojify，根据你输入的话语判断你话语的含义，并且用一个表情来表示，
并且把表情放在语句后，这样就可以实现说话时自动添加最贴切的表情。

具体参考[我的github](https://github.com/cryer/Emojify "我的keras实现")，那是一个keras版本的实现，也是Coursera作业使用的框架，我稍稍改编了一下，
里面有些实现的效果以及模型的结构，这里就不多说了，代码也很简单，容易理解。

本来这么简单感觉没必要写个博客，但是正好用pytorch复现一遍，此间遇到不少坑，所以我打算好好讲解一番。
我将会从制作自己的数据集开始，把这个问题扩展，分成几篇博文，按流程介绍我的实现历程。

`
这里我不由不说，要看你的框架掌握的怎么样，其实就是看你官方文档看的怎么样，更重要的是，你的官方源码看的怎么样，所以这几篇博文我会嵌入一些官方源码
和官方文档的内容，详细讲解如何利用它们解决自己的问题，因为当你编程的时候你会发现，遇到问题百度是没什么用的，google也不是什么问题都有的。
通过源码，你也会发现各种教程里都不太可能说到的东西。成功运行官方教程里给出的mnist程序，并不是你就会了这个框架，甚至连入门都说不上！一定要通读文档和源码！！
`
# 制作数据集

这第一篇博文我主要就想讲解一下如何在pytorch框架中制作自己的数据集，这里不得不说，源码大法好。这里的制作数据集不是
收集数据并且做成对应格式，而是已经有数据了，怎么装载到dataset里，看完博文你就了解了。

## emojify数据集构造

首先介绍一下emojify的数据集是什么样子的，其实我建议你去上面我给出的我的github上看一下，上面的介绍很清楚。这里就简单说一下，
这个数据集还是很简单的，每一个traindata就是一句话，string类型，标签就是0-4五个整形的值，代表五个表情（emoji）。testdata也一样，
但是我把所有的testdata和traindata都合在一起了，稍微增大训练集，提升泛化效果，测试我们只需要手动输入一些我们想说的话就好了，
这个项目中测试集并不是很重要。

所以最后的训练数据就是188个样本，但是为了batchsize好选，我删了8个样本，变成180个样本，存在一个csv文件中。csv文件的读取相信不用我多说，
pandas和csv模块都可以轻松读取。

## 直接加载数据

其实我们可以读取数据，然后保存在列表里，然后用np.random.shuffle打乱一下，大不了再写一个get_batch函数获取批样本，就像下面一样：

```
    def get_batchs(X,Y,batchsize = 3,batchnum = 0):
        if (batchnum*batchsize+batchsize) >= X.shape[0]:
            bx = X[batchnum * batchsize:]
            by = Y[batchnum * batchsize:]
        else:
            bx = X[batchnum * batchsize:(batchnum * batchsize + batchsize)]
            by = Y[batchnum * batchsize:(batchnum * batchsize + batchsize)]
        return np.array(bx),np.array(by)
```
 就可以在每个step时候调用一下，就可以输入数据了，那么为什么还要制作数据集呢？
 因为简单的数据集自然没有必要的，这样处理足够了，但是复杂的比较庞大的数据集呢？一点就是这样写是把所有的数据都加载进来，
 因此需要大量的内存，第二是要实现更加复杂的操作比较麻烦，又要添加更多的代码，比如多线程读取数据等等。更重要的是，数据集都不会制作，
 如何说掌握了pytorch。
 
 ## 自定义数据集
 
 回忆一下，你是怎么用pytorch实现mnist分类的，具体一点，如何加载mnist数据集的。你是直接用了torchvision.datasets.MNIST，而且
 可以指定一些参数，比如是否从云端下载数据集，对数据采用怎么样的变换等等，然后调用 Data.DataLoader，可以让数据集可迭代，
 并且可以shffule，指定batchsize等等，然后训练时就可以直接调用了，测试集也一样处理，是不是很方便。那么我们也可以这样吗？
 
 答案是肯定的。如果是图片数据集，你想做一个分类的话，直接用datasets的ImageFolder函数就可以了，只需要注意文件和文件夹的格式
 就行了。那么这里的emojify数据集呢？这里就要上源码了，我们先看官方源码的mnist是如何编写的，这里完全是我自己摸索的，然后发现
 没什么大问题，所以拿出来说一下。源码在哪看呢？github搜索vision和pytorch，分别是两部分的源码。
 
 ```
 class MNIST(data.Dataset):
    urls = [
        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',
        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',
        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',
        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',
    ]
    raw_folder = 'raw'
    processed_folder = 'processed'
    training_file = 'training.pt'
    test_file = 'test.pt'
    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):
        self.root = os.path.expanduser(root)
        self.transform = transform
        self.target_transform = target_transform
        self.train = train  # training set or test set

        if download:
            self.download()
        if not self._check_exists():
            raise RuntimeError('Dataset not found.' +
                               ' You can use download=True to download it')
        if self.train:
            self.train_data, self.train_labels = torch.load(
                os.path.join(self.root, self.processed_folder, self.training_file))
        else:
            self.test_data, self.test_labels = torch.load(
                os.path.join(self.root, self.processed_folder, self.test_file))

    def __getitem__(self, index):
        img = Image.fromarray(img.numpy(), mode='L')

        if self.transform is not None:
            img = self.transform(img)

        if self.target_transform is not None:
            target = self.target_transform(target)

        return img, target

    def __len__(self):
        if self.train:
            return len(self.train_data)
        else:
            return len(self.test_data)

    def _check_exists(self):
        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \
            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))

    def download(self):
        pass
 ```
 上面是主要代码，download被我删了，这里也不需要，接下来我们直接进行修改，怎么改呢，首先看__init__方法，赋值部分
 都不怎么需要改，虽然本例中几个都用不到，download不需要，所以上面可以直接改成pass，然后把下面的实现删去，
 train肯定是True，因为没有测试集，所以else的部分就pass，if self.train:的部分就读取我们的csv数据就好了，
 这里string的数据要换成index，我一开始没有，直接加载数据，然后出错，查看源码发现，因为数据会在源码里帮你转化成torch的Tensor，
 而torch里没有string的Tensor的，所以要变换成词汇表里的索引。_check_exists也不需要，删去，__len__里面train的值改成我们的样本数180，
 测试集没有，就是0喽。这样就剩__getitem__了，顾名思义，就是获取item的值，官方在这个函数下标注
 tuple: (image, target) where target is index of the target class，也就是获取index索引的数据，这也很简单。整理一下，改成如下：

```
 class emojiDataset(Data.Dataset):
    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):
        self.root = root
        self.transform = transform
        self.target_transform = target_transform
        self.train = train
        if download:
            pass
        if self.train:
            traindata,trainlabels = read_csv(os.path.join(self.root,'mytrain.csv'))
            self.train_data = sentences_to_indices(traindata, word_to_index, 10)
            self.train_labels = trainlabels
            # self.train_labels = convert_to_one_hot(trainlabels, C=5)
        else:
            pass
    def __getitem__(self, index):
        if self.train:
            data, target = self.train_data[index], self.train_labels[index]
        else:
            pass
        if self.transform is not None:
            pass
        if self.target_transform is not None:
            pass
        return data, target
    def __len__(self):
        if self.train:
            return 180
        else:
            return 0
 ```
可以看到，其实没怎么修改，然后iter一下，print（next（iter））测试，发现没有任何问题，就是这么简单。
注意到这个问题比较简单，所以很多函数都是pass，你当然可以自由编写，适应你的项目要求。
 
实例化一下，用dataloader试一下，看看是不是也可以，结果自然是可以的。

# 结论

这样数据集的准备就ok了，剩下就是定义模型和训练了。
